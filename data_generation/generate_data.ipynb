{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from lxml import html\n",
    "# %pip install --upgrade --quiet langchain langchain-community langchainhub langchain-chroma bs4\n",
    "import boto3\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.globals import set_debug\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import minify_html\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from collections import OrderedDict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude3_5_sonnet_config_new():\n",
    "\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\",\n",
    "        aws_access_key_id=os.getenv(\"KEY_ID\"),\n",
    "        aws_secret_access_key=os.getenv(\"ACCESS_KEY\"),\n",
    "        aws_session_token=os.getenv(\"SESSION_TOKEN\"))\n",
    "    \n",
    "    model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "    model_kwargs =  {\n",
    "        \"max_tokens\": 4096,  # set maximum token generation\n",
    "        \"temperature\": 0.7,  # increased for more creative outputs\n",
    "        \"top_k\": 100,        # increased to allow more diverse token selection\n",
    "        \"top_p\": 0.85,       # increased to encourage more creative sampling\n",
    "        \"stop_sequences\": [\"\\n\\nhuman\"],\n",
    "    }\n",
    "\n",
    "    llm = ChatBedrock(\n",
    "        client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9ecba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_result(content, tag_name=\"csv_data\"):\n",
    "    pattern = r'<'+tag_name+'>(.*?)</'+tag_name+'>'\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4b06c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calude_response(system_message, human_message):\n",
    "    \n",
    "    # create prompt template\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{human_input}\")\n",
    "    ]\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    # set llm model parameters\n",
    "    llm = claude3_5_sonnet_config_new() # # previously 0.2 and top k 80 : mostly worked\n",
    "\n",
    "    # create chain\n",
    "    chain = prompt | llm | StrOutputParser() #| RunnableLambda(extract_result)\n",
    "\n",
    "    # invoke chain\n",
    "    response = chain.invoke({\"human_input\" : human_message})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_msg(month, persona):\n",
    "\n",
    "    system_message = \"You are a synthetic data generator, and you can generate data according to the instructions provided to you which resembles to real life data.\"\n",
    "        \n",
    "    # read human_prompt from file\n",
    "    with open(\"human_prompt.txt\", \"r\") as file:\n",
    "        human_message = \"\"\"\n",
    "            Generate user transaction data for US based citizen for \"\"\"+month+\"\"\" month, consider on average 35 transactions. There should be some reoccurring transactions. Generate data in csv format. Include all the debit and credit transaction for an user, include salary credit as well. Make data realistic. Date must be in YYYY/MM/DD format. \n",
    "\n",
    "            Here is an example schema  \n",
    "            User Id Txn ID Txn Amount Txn Date Txn Category Txn Mode Merchant Code Merchant Name Payment Network Issuer Name  \n",
    "            US001 B002 788 21/06/25 shopping Credit Card CK32 Amazon VISA BOA \n",
    "\n",
    "            Generated data must be between <csv_data> tag.\n",
    "            \n",
    "            Following is user characterises, but you can add more characterises: \n",
    "            \"\"\"+persona \n",
    "\n",
    "        human_message += file.read()\n",
    "\n",
    "    return system_message, human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f39a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " Saved response for January month and persona 0\n",
      "---------------------------\n",
      " Saved response for January month and persona 0\n",
      "---------------------------\n",
      " Saved response for February month and persona 0\n",
      "---------------------------\n",
      " Saved response for February month and persona 0\n",
      "---------------------------\n",
      " Saved response for March month and persona 0\n",
      "---------------------------\n",
      " Saved response for March month and persona 0\n",
      "---------------------------\n",
      " Saved response for April month and persona 0\n",
      "---------------------------\n",
      " Saved response for April month and persona 0\n",
      "---------------------------\n",
      " Saved response for May month and persona 0\n",
      "---------------------------\n",
      " Saved response for May month and persona 0\n",
      "---------------------------\n",
      " Saved response for June month and persona 0\n",
      "---------------------------\n",
      " Saved response for June month and persona 0\n",
      "---------------------------\n",
      " Saved response for January month and persona 1\n",
      "---------------------------\n",
      " Saved response for January month and persona 1\n",
      "---------------------------\n",
      " Saved response for February month and persona 1\n",
      "---------------------------\n",
      " Saved response for February month and persona 1\n",
      "---------------------------\n",
      " Saved response for March month and persona 1\n",
      "---------------------------\n",
      " Saved response for March month and persona 1\n",
      "---------------------------\n",
      " Saved response for April month and persona 1\n",
      "---------------------------\n",
      " Saved response for April month and persona 1\n",
      "---------------------------\n",
      " Saved response for May month and persona 1\n",
      "---------------------------\n",
      " Saved response for May month and persona 1\n",
      "---------------------------\n",
      " Saved response for June month and persona 1\n",
      "---------------------------\n",
      " Saved response for June month and persona 1\n",
      "---------------------------\n",
      " Saved response for January month and persona 2\n",
      "---------------------------\n",
      " Saved response for January month and persona 2\n",
      "---------------------------\n",
      " Saved response for February month and persona 2\n",
      "---------------------------\n",
      " Saved response for February month and persona 2\n",
      "---------------------------\n",
      " Saved response for March month and persona 2\n",
      "---------------------------\n",
      " Saved response for March month and persona 2\n",
      "---------------------------\n",
      " Saved response for April month and persona 2\n",
      "---------------------------\n",
      " Saved response for April month and persona 2\n",
      "---------------------------\n",
      " Saved response for May month and persona 2\n",
      "---------------------------\n",
      " Saved response for May month and persona 2\n",
      "---------------------------\n",
      " Saved response for June month and persona 2\n",
      "---------------------------\n",
      " Saved response for June month and persona 2\n",
      "---------------------------\n",
      " Saved response for January month and persona 3\n",
      "---------------------------\n",
      " Saved response for January month and persona 3\n",
      "---------------------------\n",
      " Saved response for February month and persona 3\n",
      "---------------------------\n",
      " Saved response for February month and persona 3\n",
      "---------------------------\n",
      " Saved response for March month and persona 3\n",
      "---------------------------\n",
      " Saved response for March month and persona 3\n",
      "---------------------------\n",
      " Saved response for April month and persona 3\n",
      "---------------------------\n",
      " Saved response for April month and persona 3\n",
      "---------------------------\n",
      " Saved response for May month and persona 3\n",
      "---------------------------\n",
      " Saved response for May month and persona 3\n",
      "---------------------------\n",
      " Saved response for June month and persona 3\n",
      "---------------------------\n",
      " Saved response for June month and persona 3\n"
     ]
    }
   ],
   "source": [
    "personas_rahul = [\n",
    "    \"young age | Male| Average spending| | Party| middleclass| card holding 1| No EMI \",\n",
    "    \"Middle age | Male| Average spending| | Party| entertainment | food | middleclass| card holding 1| No EMI \",\n",
    "    \"young age | Male| Average spending| | fashion | nerd| fitness enthusiast |middleclass| card holding 1| No EMI\",\n",
    "    \"old age | Female | high spending| | travel | nerd| rich| card holding 2| With emi or loan \"\n",
    "]\n",
    "\n",
    "personas_krishna = [\n",
    "    \"Middle Age|  Male| luxury| Family person| upper middleclass| card holding 3| with EMI \",\n",
    "    \"old age | Male| Average spending| Party| middleclass| card holding 1| No EMI \",\n",
    "    \"young age | Female| Stingy spender| savings mindset| Middle class| Ed tech spender| card holding |NO EMI \",\n",
    "    \"young age | Male | Gambler | party | saving mindset | upper middle class | with emi  \"\n",
    "]\n",
    "\n",
    "for i,persona in enumerate(personas_krishna):\n",
    "    for month in [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\"]:\n",
    "        for duration in [\"first\", \"last\"]:\n",
    "            system_message, human_message = get_prompt_msg(month+\" \"+duration+\" 15 days\", persona)\n",
    "\n",
    "            response = get_calude_response(system_message, human_message)\n",
    "            # print(response)\n",
    "\n",
    "            # extract csv data from response\n",
    "            csv_data = extract_result(response, tag_name=\"csv_data\")\n",
    "\n",
    "            # save response to file\n",
    "            with open(f\"data_generation/transaction_data/krishna/user_{i}_month_{month}\"+\"_\"+duration+\"_15_days\"+\".csv\", \"w\") as f:\n",
    "                f.write(csv_data)\n",
    "            print(\"---------------------------\\n Saved response for \"+month+\" month and persona \"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd1bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a generated CSV dataset for a US-based citizen's transactions in January, based on the characteristics and categories you provided:\n",
      "\n",
      "<csv_data>\n",
      "User Id,Txn ID,Txn Amount,Txn Date,Txn Category,Txn Mode,Merchant Code,Merchant Name,Payment Network,Issuer Name\n",
      "US001,A001,3500.00,2024/01/15,INCOME_WAGES,Direct Deposit,EMP01,TechCorp Inc.,ACH,Chase Bank\n",
      "US001,B001,-45.67,2024/01/01,FOOD_AND_DRINK_GROCERIES,Credit Card,GR01,Whole Foods,VISA,Chase Bank\n",
      "US001,B002,-12.99,2024/01/01,ENTERTAINMENT_MUSIC_AND_AUDIO,Credit Card,SP01,Spotify,VISA,Chase Bank\n",
      "US001,B003,-14.99,2024/01/01,ENTERTAINMENT_TV_AND_MOVIES,Credit Card,NF01,Netflix,VISA,Chase Bank\n",
      "US001,B004,-89.99,2024/01/02,GENERAL_MERCHANDISE_CLOTHING_AND_ACCESSORIES,Credit Card,AM01,Amazon,VISA,Chase Bank\n",
      "US001,B005,-35.50,2024/01/03,FOOD_AND_DRINK_RESTAURANT,Credit Card,RS01,Cheesecake Factory,VISA,Chase Bank\n",
      "US001,B006,-50.00,2024/01/04,TRANSPORTATION_GAS,Debit Card,SH01,Shell,VISA,Chase Bank\n",
      "US001,B007,-15.99,2024/01/05,FOOD_AND_DRINK_FAST_FOOD,Credit Card,MC01,McDonald's,VISA,Chase Bank\n",
      "US001,B008,-75.00,2024/01/06,PERSONAL_CARE_GYMS_AND_FITNESS_CENTERS,Credit Card,GY01,LA Fitness,VISA,Chase Bank\n",
      "US001,B009,-22.50,2024/01/07,ENTERTAINMENT_VIDEO_GAMES,Credit Card,ST01,Steam,VISA,Chase Bank\n",
      "US001,B010,-1200.00,2024/01/08,RENT_AND_UTILITIES_RENT,Bank Transfer,APT01,Sunset Apartments,ACH,Chase Bank\n",
      "US001,B011,-85.00,2024/01/08,RENT_AND_UTILITIES_INTERNET_AND_CABLE,Credit Card,CM01,Comcast,VISA,Chase Bank\n",
      "US001,B012,-60.00,2024/01/08,RENT_AND_UTILITIES_GAS_AND_ELECTRICITY,Credit Card,PG01,PG&E,VISA,Chase Bank\n",
      "US001,B013,-40.00,2024/01/08,RENT_AND_UTILITIES_WATER,Credit Card,WU01,Water Utility Co.,VISA,Chase Bank\n",
      "US001,B014,-55.00,2024/01/09,FOOD_AND_DRINK_GROCERIES,Debit Card,TJ01,Trader Joe's,VISA,Chase Bank\n",
      "US001,B015,-30.00,2024/01/10,ENTERTAINMENT_SPORTING_EVENTS_AMUSEMENT_PARKS_AND_MUSEUMS,Credit Card,TM01,Ticketmaster,VISA,Chase Bank\n",
      "US001,B016,-25.99,2024/01/11,FOOD_AND_DRINK_RESTAURANT,Credit Card,CH01,Chipotle,VISA,Chase Bank\n",
      "US001,B017,-45.00,2024/01/12,TRANSPORTATION_GAS,Debit Card,EX01,Exxon,VISA,Chase Bank\n",
      "US001,B018,-18.50,2024/01/13,FOOD_AND_DRINK_COFFEE,Credit Card,SB01,Starbucks,VISA,Chase Bank\n",
      "US001,B019,-65.00,2024/01/14,GENERAL_MERCHANDISE_ELECTRONICS,Credit Card,BB01,Best Buy,VISA,Chase Bank\n",
      "US001,B020,-40.00,2024/01/15,PERSONAL_CARE_HAIR_AND_BEAUTY\n"
     ]
    }
   ],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e440f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def combine_csv(file_start_with):\n",
    "    # Pattern to match all CSVs starting with 'user_0'\n",
    "    csv_files = glob.glob(\"data_generation/transaction_data/krishna/\"+file_start_with+\"*.csv\")\n",
    "\n",
    "    # List to hold DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Read each CSV file (skip header after first file)\n",
    "    for i, file in enumerate(csv_files):\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save to a new CSV\n",
    "    combined_df.to_csv(\"data_generation/transaction_data/krishna/\"+file_start_with+\".csv\", index=False)\n",
    "\n",
    "\n",
    "for file_start_with in [\"user_0\",\"user_1\",\"user_2\",\"user_3\"]:\n",
    "    combine_csv(file_start_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # Process each combined CSV file\n",
    "# for file_start_with in [\"user_0\"]:\n",
    "#     file_path = f\"transaction_data/rahul/{file_start_with}.csv\"\n",
    "#     if not os.path.exists(file_path):\n",
    "#         continue\n",
    "\n",
    "#     df = pd.read_csv(file_path)\n",
    "\n",
    "#     # Try to find the date column (case-insensitive)\n",
    "#     date_col = None\n",
    "#     for col in df.columns:\n",
    "#         if col.strip().lower() in [\"txn date\", \"date\"]:\n",
    "#             date_col = col\n",
    "#             break\n",
    "\n",
    "#     if date_col:\n",
    "#         def fix_date(val):\n",
    "#             val = str(val).strip()\n",
    "#             # Try YYYY-MM-DD\n",
    "#             if re.match(r\"\\d{4}-\\d{2}-\\d{2}\", val):\n",
    "#                 return pd.to_datetime(val, format=\"%Y-%m-%d\").strftime(\"%Y/%m/%d\")\n",
    "#             # Try DD/MM/YY or DD/MM/YYYY\n",
    "#             if re.match(r\"\\d{2}/\\d{2}/\\d{2,4}\", val):\n",
    "#                 try:\n",
    "#                     # Try DD/MM/YYYY\n",
    "#                     return pd.to_datetime(val, format=\"%d/%m/%Y\").strftime(\"%Y/%m/%d\")\n",
    "#                 except:\n",
    "#                     # Try DD/MM/YY\n",
    "#                     return pd.to_datetime(val, format=\"%d/%m/%y\").strftime(\"%Y/%m/%d\")\n",
    "#             # Try MM/DD/YYYY\n",
    "#             if re.match(r\"\\d{2}/\\d{2}/\\d{4}\", val):\n",
    "#                 try:\n",
    "#                     return pd.to_datetime(val, format=\"%m/%d/%Y\").strftime(\"%Y/%m/%d\")\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             # Already in YYYY/MM/DD\n",
    "#             if re.match(r\"\\d{4}/\\d{2}/\\d{2}\", val):\n",
    "#                 return val\n",
    "#             # If not matched, return as is\n",
    "#             return val\n",
    "\n",
    "#         df[date_col] = df[date_col].apply(fix_date)\n",
    "#         df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
